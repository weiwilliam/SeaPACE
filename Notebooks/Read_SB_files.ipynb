{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb6c6e8-cc32-4736-815e-8aa7d8277957",
   "metadata": {},
   "source": [
    "### Reading in SeaBASS (.sb) Datafiles\n",
    "\n",
    "##### Ceridwyn Hunter - 2025/08/04\n",
    "_____________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086677a-d43e-4f62-8b2e-dfced48c4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import geopandas as gpd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from holoviews import opts\n",
    "from datetime import datetime\n",
    "from holoviews.element.tiles import CartoLight\n",
    "\n",
    "hv.extension('bokeh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8e78f-bb5d-4be9-8fb2-8610714493ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 1) DEFINE SB_PARSER ───────────────────────────────────────────────────────\n",
    "\n",
    "def parse_sb(file_path):\n",
    "    text = Path(file_path).read_text()\n",
    "    header, body = text.split('/end_header', 1)\n",
    "\n",
    "    # 1a) extract header entries\n",
    "    metadata = {}\n",
    "    for line in header.splitlines():\n",
    "        if not line.startswith('/'): \n",
    "            continue\n",
    "        if '=' not in line:    \n",
    "            continue\n",
    "        key, val = line[1:].split('=', 1)\n",
    "        key, val = key.strip(), re.sub(r'\\[.*?\\]', '', val).strip()\n",
    "        if key in {\n",
    "            'station','data_file_name',\n",
    "            'start_date','end_date',\n",
    "            'start_time','end_time',\n",
    "            'fields',\n",
    "            'north_latitude','south_latitude',\n",
    "            'west_longitude','east_longitude'\n",
    "        }:\n",
    "            metadata[key] = val\n",
    "\n",
    "    # 1b) parse the /fields list & store it\n",
    "    fields_list = [f.strip() for f in metadata['fields'].split(',')]\n",
    "    metadata['fields_list'] = fields_list\n",
    "\n",
    "    # 1c) read the body into a DataFrame\n",
    "    df = pd.read_csv(\n",
    "        StringIO(body.strip()),\n",
    "        sep=',',\n",
    "        names=fields_list,\n",
    "        comment='/'\n",
    "    )\n",
    "\n",
    "    # 1d) detect single‐spectrum files & fill lat/lon if missing\n",
    "    is_spectrum = ('lat' not in df.columns or 'lon' not in df.columns)\n",
    "    metadata['single_spectrum'] = is_spectrum\n",
    "    if is_spectrum:\n",
    "        lat0 = float(metadata.get('north_latitude', metadata.get('south_latitude', 0)))\n",
    "        lon0 = float(metadata.get('west_longitude',  metadata.get('east_longitude',  0)))\n",
    "        df['lat'], df['lon'] = lat0, lon0\n",
    "\n",
    "    # 1e) ensure date/time exist\n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = metadata['start_date']\n",
    "    if 'time' not in df.columns:\n",
    "        df['time'] = metadata['start_time']\n",
    "\n",
    "    # 1f) build datetime column\n",
    "    df['datetime'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['time'])\n",
    "\n",
    "    # 1g) parse header start/end datetimes\n",
    "    def _pd(d, t):\n",
    "        t_clean = re.sub(r'\\[.*?\\]', '', t)\n",
    "        dfmt = '%Y-%m-%d' if '-' in d else '%Y%m%d'\n",
    "        return datetime.strptime(f\"{d} {t_clean}\", f\"{dfmt} %H:%M:%S\")\n",
    "    metadata['start_datetime'] = _pd(metadata['start_date'], metadata['start_time'])\n",
    "    metadata['end_datetime']   = _pd(metadata['end_date'],   metadata['end_time'])\n",
    "\n",
    "    # 1h) keep only the five columns you care about\n",
    "    df = df[['date','time','lat','lon' '','datetime']]\n",
    "\n",
    "    return metadata, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70504b-5b8b-4250-b76f-3c173cfe4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2.a) COLLECT & PREPARE ALL FILES ──────────────────────────────────────────\n",
    "\n",
    "root = Path(\"/home/jovyan/shared-public/pace-hackweek/SeePACE/Hackweek_PACE-PAX_09_22-28\")\n",
    "metadata_list = []\n",
    "search_types = ['Rrs', 'AOP'] #  Add additional search parameters if desired ***********************\n",
    "\n",
    "for sb in root.rglob('*.sb'):\n",
    "    meta, df = parse_sb(sb)\n",
    "\n",
    "    # collapse spectral files to exactly one row\n",
    "    if meta['single_spectrum']:\n",
    "        df = df.head(1)\n",
    "\n",
    "    meta['data'] = df\n",
    "    # detect which of your search_types appear in the original fields\n",
    "    meta['Data_Type'] = [\n",
    "        t for t in search_types\n",
    "        if any(t in f for f in meta['fields_list'])\n",
    "    ]\n",
    "    metadata_list.append(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826b12a-92c2-4290-a5c8-11f2f1eb3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2.b) CONFIRM PATH/FILES EXIST ──────────────────────────────────────────\n",
    "\n",
    "# i. Does that directory exist?\n",
    "print(\"Exists (T/F) \", root.exists())\n",
    "print(\"Is directory (T/F) \", root.is_dir())\n",
    "\n",
    "# ii. If it does, list the first few entries to check\n",
    "if root.exists() and root.is_dir():\n",
    "    for i, p in enumerate(root.iterdir()):\n",
    "        print(\"-\", p.name)\n",
    "        if i >= 9:   # only showing the first 10 items\n",
    "            break\n",
    "else:\n",
    "    print(\"Path not found—check your spelling or mount points.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b1a2e1-4848-413d-a85f-60328370dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 3) BUILD SUMMARY DATAFRAME ─────────────────────────────────────────────\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'Station':        m['station'],\n",
    "    'Data_File_Name': m['data_file_name'],\n",
    "    'Start_Datetime': m['start_datetime'],\n",
    "    'End_Datetime':   m['end_datetime'],\n",
    "    'Data_Type':      m['Data_Type']\n",
    "} for m in metadata_list])\n",
    "\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cdd4e-c8de-4ae6-9acf-b4cb424ae085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4) BUILD & CONCATENATE XR DATASETS ─────────────────────────────────────\n",
    "\n",
    "ds_list    = []\n",
    "file_names = []\n",
    "\n",
    "for m in metadata_list:\n",
    "    df = m['data'].reset_index(drop=True).reset_index().rename(columns={'index':'record'})\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            'lat':      ('record', df['lat']),\n",
    "            'lon':      ('record', df['lon']),\n",
    "            'datetime': ('record', df['datetime'])\n",
    "        },\n",
    "        coords={'record': df['record']}\n",
    "    )\n",
    "    # promote to a 2-D Dataset along new 'file' dim\n",
    "    ds = ds.expand_dims(file=[m['data_file_name']])\n",
    "    ds_list.append(ds)\n",
    "    file_names.append(m['data_file_name'])\n",
    "\n",
    "ds_combined = xr.concat(\n",
    "    ds_list,\n",
    "    dim='file',\n",
    "    coords='minimal',\n",
    "    compat='override'\n",
    ")\n",
    "\n",
    "print(ds_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88405310-b3ce-4e15-b094-64af4d7430e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metadata_list[30]['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e2d22-c885-4661-a634-dbd148b87775",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "### Initial Plot of SeaBASS Datafiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b4dcc-9d37-4fe6-9e73-096ca2b95ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import holoviews as hv\n",
    "from holoviews.element.tiles import CartoLight\n",
    "from bokeh.models import HoverTool\n",
    "import math\n",
    "\n",
    "# Initialize HoloViews for Bokeh\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Helper: convert lon/lat → Web Mercator\n",
    "def lonlat_to_mercator(lon, lat):\n",
    "    k = 6378137.0\n",
    "    x = lon * (math.pi/180.0) * k\n",
    "    y = math.log(math.tan((90 + lat) * math.pi/360.0)) * k\n",
    "    return x, y\n",
    "\n",
    "# Prepare list of HoloViews elements\n",
    "elements = []\n",
    "\n",
    "for m in metadata_list:\n",
    "    name = m['data_file_name']\n",
    "    df = m['data'].copy()\n",
    "\n",
    "    # Annotate for hover\n",
    "    df['File']          = name\n",
    "    df['Start_str']     = m['start_datetime'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    df['End_str']       = m['end_datetime'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    df['Data_Type_str'] = \", \".join(m['Data_Type'])\n",
    "\n",
    "    # Project to Web Mercator\n",
    "    df['merc_x'], df['merc_y'] = zip(*[\n",
    "        lonlat_to_mercator(lon, lat)\n",
    "        for lon, lat in zip(df['lon'], df['lat'])\n",
    "    ])\n",
    "\n",
    "    # If multiple points, draw a line\n",
    "    if len(df) > 1:\n",
    "        coords = df[['merc_x','merc_y']].values\n",
    "        line = hv.Path(coords, kdims=['x','y']).opts(\n",
    "            color='red',\n",
    "            line_width=2\n",
    "        )\n",
    "        elements.append(line)\n",
    "\n",
    "    # Always draw points\n",
    "    points = hv.Points(\n",
    "        df,\n",
    "        kdims=['merc_x','merc_y'],\n",
    "        vdims=['File','Start_str','End_str','Data_Type_str']\n",
    "    ).opts(\n",
    "        size=6,\n",
    "        color='blue',\n",
    "        tools=[\n",
    "            HoverTool(tooltips=[\n",
    "                ('File', '@File'),\n",
    "                ('Start','@Start_str'),\n",
    "                ('End',  '@End_str'),\n",
    "                ('Type', '@Data_Type_str')\n",
    "            ]),\n",
    "            'wheel_zoom','pan'\n",
    "        ],\n",
    "        active_tools=['wheel_zoom']\n",
    "    )\n",
    "    elements.append(points)\n",
    "\n",
    "# Basemap\n",
    "tiles = CartoLight().opts(\n",
    "    width=900,\n",
    "    height=700,\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    tools=[],\n",
    "    active_tools=[]\n",
    ")\n",
    "\n",
    "# Overlay everything\n",
    "overlay = tiles * hv.Overlay(elements)\n",
    "overlay.opts(title=\"Trajectories & Points of .sb Files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb4198-1425-4aec-b755-ae87f8c62e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import holoviews as hv\n",
    "from holoviews.element.tiles import CartoLight\n",
    "from holoviews import opts\n",
    "from bokeh.models import HoverTool\n",
    "import math\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "# Initialize HoloViews for Bokeh\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Helper: convert lon/lat → Web Mercator\n",
    "def lonlat_to_mercator(lon, lat):\n",
    "    k = 6378137.0\n",
    "    x = lon * (math.pi/180.0) * k\n",
    "    y = math.log(math.tan((90 + lat) * math.pi/360.0)) * k\n",
    "    return x, y\n",
    "\n",
    "# 1) Build trajectory lines and collect all point records\n",
    "elements = []\n",
    "all_points = []\n",
    "for m in metadata_list:\n",
    "    name = m['data_file_name']\n",
    "    df = m['data'].copy()\n",
    "\n",
    "    # Annotate for grouping\n",
    "    df['File']          = name\n",
    "    df['Start_str']     = m['start_datetime'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['End_str']       = m['end_datetime'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['Data_Type_str'] = ', '.join(m['Data_Type'])\n",
    "\n",
    "    # Project coordinates\n",
    "    df['merc_x'], df['merc_y'] = zip(*[\n",
    "        lonlat_to_mercator(lon, lat) for lon, lat in zip(df['lon'], df['lat'])\n",
    "    ])\n",
    "\n",
    "    # Draw trajectory line if multi-point\n",
    "    if len(df) > 1:\n",
    "        coords = df[['merc_x','merc_y']].values\n",
    "        elements.append(\n",
    "            hv.Path(coords, kdims=['x','y']).opts(color='red', line_width=2)\n",
    "        )\n",
    "\n",
    "    # Add to global points list\n",
    "    all_points.append(df)\n",
    "\n",
    "# 2) Concatenate all points and group duplicates by location\n",
    "full_df = pd.concat(all_points, ignore_index=True)\n",
    "\n",
    "# Combine unique filenames into a comma-separated string and wrap lines\n",
    "\n",
    "def wrap_files(vals):\n",
    "    u = sorted(set(vals))\n",
    "    joined = \", \".join(u)\n",
    "    # wrap into lines ≤30 chars, then convert newlines to <br>\n",
    "    return textwrap.fill(joined, width=100).replace(\"\\n\", '<br>')\n",
    "\n",
    "# Group and combine hover fields\n",
    "grouped = full_df.groupby(['merc_x','merc_y'], as_index=False).agg({\n",
    "    'File':          wrap_files,\n",
    "    'Start_str':     lambda vals: '<br>'.join(sorted(set(vals))),\n",
    "    'End_str':       lambda vals: '<br>'.join(sorted(set(vals))),\n",
    "    'Data_Type_str': lambda vals: '<br>'.join(sorted(set(vals)))\n",
    "})\n",
    "\n",
    "# 3) Single Points layer with combined hover data\n",
    "elements.append(\n",
    "    hv.Points(\n",
    "        grouped,\n",
    "        kdims=['merc_x','merc_y'],\n",
    "        vdims=['File','Start_str','End_str','Data_Type_str']\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4) Unified HoverTool snapping to data with HTML-safe tooltips\n",
    "hover = HoverTool(\n",
    "    tooltips=\"\"\"\n",
    "    <div style=\\\"max-width:600px;\\\">  <!-- constrain width -->\n",
    "      <strong>File:</strong><br>@File{safe}<br>\n",
    "      <strong>Start:</strong> @Start_str<br>\n",
    "      <strong>End:</strong> @End_str<br>\n",
    "      <strong>Type:</strong> @Data_Type_str\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    point_policy='snap_to_data'\n",
    ")\n",
    "# 5) Basemap) Basemap\n",
    "tiles = CartoLight().opts(\n",
    "    width=900, height=700,\n",
    "    xaxis=None, yaxis=None,\n",
    "    tools=[], active_tools=[]\n",
    ")\n",
    "\n",
    "# 6) Overlay trajectories + combined points\n",
    "overlay = tiles * hv.Overlay(elements)\n",
    "\n",
    "# 7) Style Points only and hide path legend\n",
    "overlay = overlay.opts(\n",
    "    opts.Points(\n",
    "        size=6,\n",
    "        color='blue',\n",
    "        tools=[hover, 'wheel_zoom', 'pan'],\n",
    "        active_tools=['wheel_zoom']\n",
    "    ),\n",
    "    opts.Path(show_legend=False)\n",
    ")\n",
    "\n",
    "# 8) Add title and render\n",
    "overlay = overlay.opts(title='Trajectories & Combined Points of .sb Files')\n",
    "\n",
    "overlay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee34ba-367c-42ae-b143-272664062c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from holoviews.element.tiles import CartoLight\n",
    "from bokeh.models import HoverTool\n",
    "import math, pandas as pd, textwrap\n",
    "\n",
    "# Initialize HoloViews and Panel for Bokeh\n",
    "hv.extension('bokeh')  \n",
    "pn.extension()\n",
    "\n",
    "# Helper: convert lon/lat → Web Mercator\n",
    "def lonlat_to_mercator(lon, lat):\n",
    "    k = 6378137.0\n",
    "    x = lon * (math.pi/180.0) * k\n",
    "    y = math.log(math.tan((90 + lat) * math.pi/360.0)) * k\n",
    "    return x, y\n",
    "\n",
    "# --- assemble full DataFrame of points ---\n",
    "all_pts = []\n",
    "for m in metadata_list:\n",
    "    df = m['data'].copy()\n",
    "    df['File']          = m['data_file_name']\n",
    "    df['datetime']      = m['start_datetime']\n",
    "    df['Data_Type_str'] = ', '.join(m['Data_Type'])\n",
    "    df['merc_x'], df['merc_y'] = zip(*[\n",
    "        lonlat_to_mercator(lon, lat) for lon, lat in zip(df['lon'], df['lat'])\n",
    "    ])\n",
    "    all_pts.append(df)\n",
    "full_df = pd.concat(all_pts, ignore_index=True)\n",
    "\n",
    "# Wrap-and-merge filenames for hover\n",
    "def wrap_files(vals):\n",
    "    names = sorted(set(vals))\n",
    "    joined = \", \".join(names)\n",
    "    return textwrap.fill(joined, width=30).replace(\"\\n\", '<br>')\n",
    "\n",
    "# Base tiles\n",
    "# compute global Mercator extent and add padding for fixed view\n",
    "x_min, x_max = full_df['merc_x'].min(), full_df['merc_x'].max()\n",
    "y_min, y_max = full_df['merc_y'].min(), full_df['merc_y'].max()\n",
    "# add 5% padding on each side\n",
    "pad_x = (x_max - x_min) * 0.05\n",
    "pad_y = (y_max - y_min) * 0.05\n",
    "\n",
    "base_tiles = CartoLight().opts(\n",
    "    width=800, height=600,\n",
    "    xaxis=None, yaxis=None,\n",
    "    tools=[], active_tools=[],\n",
    "    xlim=(x_min - pad_x, x_max + pad_x),  # padded horizontal range\n",
    "    ylim=(y_min - pad_y, y_max + pad_y)   # padded vertical range\n",
    ")\n",
    "\n",
    "# HoverTool\n",
    "hover = HoverTool(\n",
    "    tooltips=\"\"\"\n",
    "    <div style='max-width:200px;'>\n",
    "      <strong>Time:</strong> @datetime{%F}<br>\n",
    "      <strong>File:</strong> @File{safe}<br>\n",
    "      <strong>Type:</strong> @Data_Type_str\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    formatters={'@datetime':'datetime'},\n",
    "    point_policy='snap_to_data'\n",
    ")\n",
    "\n",
    "# Plotting function\n",
    "def make_plot(selected_date=None, show_all=False):\n",
    "    if show_all:\n",
    "        df = full_df\n",
    "    else:\n",
    "        # show only that day's points\n",
    "        df = full_df[full_df['datetime'].dt.date == pd.to_datetime(selected_date).date()]\n",
    "    grouped = df.groupby(['merc_x','merc_y'], as_index=False).agg({\n",
    "        'datetime':       'max',\n",
    "        'File':           wrap_files,\n",
    "        'Data_Type_str':  lambda v: '<br>'.join(sorted(set(v)))\n",
    "    })\n",
    "    pts = hv.Points(\n",
    "        grouped,\n",
    "        kdims=['merc_x','merc_y'],\n",
    "        vdims=['datetime','File','Data_Type_str']\n",
    "    ).opts(\n",
    "        size=8, color='blue', tools=[hover, 'wheel_zoom', 'pan'], active_tools=['wheel_zoom']\n",
    "    )\n",
    "    return base_tiles * pts\n",
    "\n",
    "# Widgets: Date slider + 'Show All' toggle\n",
    "dates = full_df['datetime'].dt.date\n",
    "slider = pn.widgets.DateSlider(\n",
    "    name='Day',\n",
    "    start=dates.min(),\n",
    "    end=dates.max(),\n",
    "    value=dates.min(),\n",
    "    step=1,\n",
    "    width=800\n",
    ")\n",
    "toggle = pn.widgets.Checkbox(\n",
    "    name='Show All Days',\n",
    "    value=False\n",
    ")\n",
    "\n",
    "# Callback\n",
    "@pn.depends(day=slider.param.value, show_all=toggle.param.value)\n",
    "def update(day, show_all):\n",
    "    return make_plot(day, show_all)\n",
    "\n",
    "# Layout\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(slider, toggle),\n",
    "    update\n",
    ")\n",
    "\n",
    "dashboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c198029-7b46-4a32-b3c7-22620455a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from holoviews.element.tiles import CartoLight\n",
    "from bokeh.models import HoverTool\n",
    "import math, pandas as pd, textwrap\n",
    "\n",
    "# Initialize HoloViews and Panel for Bokeh\n",
    "hv.extension('bokeh')  \n",
    "pn.extension()\n",
    "\n",
    "# Helper: convert lon/lat → Web Mercator\n",
    "def lonlat_to_mercator(lon, lat):\n",
    "    k = 6378137.0\n",
    "    x = lon * (math.pi/180.0) * k\n",
    "    y = math.log(math.tan((90 + lat) * math.pi/360.0)) * k\n",
    "    return x, y\n",
    "\n",
    "# --- assemble full DataFrame of points ---\n",
    "all_pts = []\n",
    "for m in metadata_list:\n",
    "    df = m['data'].copy()\n",
    "    df['File']          = m['data_file_name']\n",
    "    df['datetime']      = m['start_datetime']\n",
    "    df['Data_Type_str'] = ', '.join(m['Data_Type'])\n",
    "    df['merc_x'], df['merc_y'] = zip(*[\n",
    "        lonlat_to_mercator(lon, lat) for lon, lat in zip(df['lon'], df['lat'])\n",
    "    ])\n",
    "    all_pts.append(df)\n",
    "full_df = pd.concat(all_pts, ignore_index=True)\n",
    "\n",
    "# Wrap-and-merge filenames for hover\n",
    "def wrap_files(vals):\n",
    "    names = sorted(set(vals))\n",
    "    joined = \", \".join(names)\n",
    "    return textwrap.fill(joined, width=30).replace(\"\\n\", '<br>')\n",
    "\n",
    "# Base tiles\n",
    "# compute global Mercator extent and add padding for fixed view\n",
    "x_min, x_max = full_df['merc_x'].min(), full_df['merc_x'].max()\n",
    "y_min, y_max = full_df['merc_y'].min(), full_df['merc_y'].max()\n",
    "# add 5% padding on each side\n",
    "pad_x = (x_max - x_min) * 0.05\n",
    "pad_y = (y_max - y_min) * 0.05\n",
    "\n",
    "base_tiles = CartoLight().opts(\n",
    "    width=800, height=600,\n",
    "    xaxis=None, yaxis=None,\n",
    "    tools=[], active_tools=[],\n",
    "    xlim=(x_min - pad_x, x_max + pad_x),  # padded horizontal range\n",
    "    ylim=(y_min - pad_y, y_max + pad_y)   # padded vertical range\n",
    ")\n",
    "\n",
    "# HoverTool\n",
    "hover = HoverTool(\n",
    "    tooltips=\"\"\"\n",
    "    <div style='max-width:200px;'>\n",
    "      <strong>Time:</strong> @datetime{%F}<br>\n",
    "      <strong>File:</strong> @File{safe}<br>\n",
    "      <strong>Type:</strong> @Data_Type_str\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    formatters={'@datetime':'datetime'},\n",
    "    point_policy='snap_to_data'\n",
    ")\n",
    "\n",
    "# Plotting function (with transect lines)\n",
    "def make_plot(selected_date=None, show_all=False):\n",
    "    # filter points\n",
    "    if show_all:\n",
    "        df = full_df.copy()\n",
    "    else:\n",
    "        df = full_df[full_df['datetime'].dt.date == pd.to_datetime(selected_date).date()]\n",
    "\n",
    "    # Group and merge point duplicates\n",
    "    grouped = df.groupby(['merc_x','merc_y'], as_index=False).agg({\n",
    "        'datetime':       'max',\n",
    "        'File':           wrap_files,\n",
    "        'Data_Type_str':  lambda v: '<br>'.join(sorted(set(v)))\n",
    "    })\n",
    "    pts = hv.Points(\n",
    "        grouped,\n",
    "        kdims=['merc_x','merc_y'],\n",
    "        vdims=['datetime','File','Data_Type_str']\n",
    "    ).opts(\n",
    "        size=8, color='blue', tools=[hover, 'wheel_zoom', 'pan'], active_tools=['wheel_zoom']\n",
    "    )\n",
    "\n",
    "    # Build transect lines per file\n",
    "    lines = []\n",
    "    for fname, sub in df.groupby('File'):\n",
    "        if len(sub) > 1:\n",
    "            # sort by datetime\n",
    "            sub_sorted = sub.sort_values('datetime')\n",
    "            coords = list(zip(sub_sorted['merc_x'], sub_sorted['merc_y']))\n",
    "            line = hv.Path([coords], kdims=['x','y']).opts(color='red', line_width=2)\n",
    "            lines.append(line)\n",
    "    # Combine all lines\n",
    "    if lines:\n",
    "        traj = hv.Overlay({f.name if hasattr(f, 'name') else i: f for i, f in enumerate(lines)})\n",
    "        return base_tiles * traj * pts\n",
    "    else:\n",
    "        return base_tiles * pts\n",
    "\n",
    "# Widgets: Date slider + 'Show All' toggle + 'Show All' toggle\n",
    "dates = full_df['datetime'].dt.date\n",
    "slider = pn.widgets.DateSlider(\n",
    "    name='Day',\n",
    "    start=dates.min(),\n",
    "    end=dates.max(),\n",
    "    value=dates.min(),\n",
    "    step=1,\n",
    "    width=800\n",
    ")\n",
    "toggle = pn.widgets.Checkbox(\n",
    "    name='Show All Days',\n",
    "    value=False\n",
    ")\n",
    "\n",
    "# Callback\n",
    "@pn.depends(day=slider.param.value, show_all=toggle.param.value)\n",
    "def update(day, show_all):\n",
    "    return make_plot(day, show_all)\n",
    "\n",
    "# Layout\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(slider, toggle),\n",
    "    update\n",
    ")\n",
    "\n",
    "dashboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73823c1-9353-4793-9d4d-2fe52ae1b1e5",
   "metadata": {},
   "source": [
    "_______________________________________________________\n",
    "## Next Step\n",
    "\n",
    "### Plot the same map with the hover showing a plot when you hover over with the in-situ spectra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d01c0-2865-4c54-9843-a9ea173f52a5",
   "metadata": {},
   "source": [
    "#### for those points where there is spectra at identical points, use 1 plot (and plot multiple spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e85813-7334-48ba-886a-31870204c60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
